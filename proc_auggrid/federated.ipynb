{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Customer</th>\n",
       "      <th colspan=\"3\" halign=\"left\">1</th>\n",
       "      <th colspan=\"3\" halign=\"left\">3</th>\n",
       "      <th colspan=\"3\" halign=\"left\">4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"3\" halign=\"left\">297</th>\n",
       "      <th colspan=\"2\" halign=\"left\">298</th>\n",
       "      <th colspan=\"2\" halign=\"left\">299</th>\n",
       "      <th colspan=\"3\" halign=\"left\">300</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categories</th>\n",
       "      <th>GG</th>\n",
       "      <th>GC</th>\n",
       "      <th>CL</th>\n",
       "      <th>GG</th>\n",
       "      <th>GC</th>\n",
       "      <th>CL</th>\n",
       "      <th>GG</th>\n",
       "      <th>GC</th>\n",
       "      <th>CL</th>\n",
       "      <th>GG</th>\n",
       "      <th>...</th>\n",
       "      <th>GG</th>\n",
       "      <th>GC</th>\n",
       "      <th>CL</th>\n",
       "      <th>GG</th>\n",
       "      <th>GC</th>\n",
       "      <th>GG</th>\n",
       "      <th>GC</th>\n",
       "      <th>GG</th>\n",
       "      <th>GC</th>\n",
       "      <th>CL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-07-01 00:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1710.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1930.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1082.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>5346.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-01 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1572.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1854.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>2492.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-01 01:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1208.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2718.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>3860.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>394.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-01 02:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>2526.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>3956.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>2660.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-01 02:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1194.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1568.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>412.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 725 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Customer             1                    3                 4           \\\n",
       "categories            GG      GC      CL   GG      GC   CL   GG     GC   \n",
       "2012-07-01 00:30:00  0.0  1710.0  2500.0  0.0  1930.0  0.0  0.0  168.0   \n",
       "2012-07-01 01:00:00  0.0  1572.0  2500.0  0.0  1854.0  0.0  0.0  168.0   \n",
       "2012-07-01 01:30:00  0.0  1208.0  2500.0  0.0  2718.0  0.0  0.0  164.0   \n",
       "2012-07-01 02:00:00  0.0  1088.0  2526.0  0.0   120.0  0.0  0.0  168.0   \n",
       "2012-07-01 02:30:00  0.0  1194.0   262.0  0.0   118.0  0.0  0.0  172.0   \n",
       "\n",
       "Customer                     5    ...  297                 298         299  \\\n",
       "categories               CL   GG  ...   GG     GC      CL   GG     GC   GG   \n",
       "2012-07-01 00:30:00     0.0  0.0  ...  0.0  282.0     0.0  0.0  314.0  0.0   \n",
       "2012-07-01 01:00:00     0.0  0.0  ...  0.0  514.0     0.0  0.0  254.0  0.0   \n",
       "2012-07-01 01:30:00  3860.0  0.0  ...  0.0  394.0     0.0  0.0  244.0  0.0   \n",
       "2012-07-01 02:00:00  3956.0  0.0  ...  0.0  546.0  2660.0  0.0  240.0  0.0   \n",
       "2012-07-01 02:30:00  1568.0  0.0  ...  0.0  412.0     0.0  0.0  212.0  0.0   \n",
       "\n",
       "Customer                     300                 \n",
       "categories               GC   GG     GC      CL  \n",
       "2012-07-01 00:30:00  1082.0  0.0  438.0  5346.0  \n",
       "2012-07-01 01:00:00   200.0  0.0  198.0  2492.0  \n",
       "2012-07-01 01:30:00   180.0  0.0  268.0     0.0  \n",
       "2012-07-01 02:00:00   188.0  0.0  200.0     0.0  \n",
       "2012-07-01 02:30:00    92.0  0.0  246.0     0.0  \n",
       "\n",
       "[5 rows x 725 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "TS = 48 # Time steps\n",
    "\n",
    "df = pd.read_csv('AusGrid_preprocess.csv', header=[0,1], index_col=0)\n",
    "df = df.set_index(pd.to_datetime(df.index))\n",
    "df.columns = df.columns.set_levels(df.columns.levels[0].astype('int64'), level=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8662.0\n"
     ]
    }
   ],
   "source": [
    "customers = sorted(df.columns.levels[0])\n",
    "max_values = []\n",
    "for c in customers:\n",
    "    max_values.append(df[c]['GG'].max())\n",
    "\n",
    "normalize = max(max_values)\n",
    "print(normalize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 17472, 48, 1) (299, 17472)\n"
     ]
    }
   ],
   "source": [
    "def gen_data(X, y, num_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - num_steps):        \n",
    "        Xs.append(np.reshape(X[i:(i + num_steps)], (num_steps, 1)))\n",
    "        ys.append(y[i + num_steps])\n",
    "    return np.array(Xs), np.reshape(np.array(ys), (len(ys)))\n",
    "    \n",
    "customers = sorted(df.columns.levels[0])\n",
    "x_list = []\n",
    "y_list = []\n",
    "for c in customers:\n",
    "    tmp = df[c]['GG'].to_numpy()/normalize\n",
    "    tmp_x, tmp_y = gen_data(tmp, tmp, TS)        \n",
    "    x_list.append(tmp_x)\n",
    "    y_list.append(tmp_y)\n",
    "x_data = np.array(x_list)\n",
    "y_data = np.array(y_list)\n",
    "print(x_data.shape, y_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 17472, 48, 1) (200, 17472)\n",
      "(99, 17472, 48, 1) (99, 17472)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = x_data[:200], y_data[:200]\n",
    "print(x_train.shape, y_train.shape)\n",
    "x_test, y_test = x_data[200:], y_data[200:]\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 17472, 48, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "# x_train = np.expand_dims(x_train, -1)  # 채널 차원 추가\n",
    "# x_test = np.expand_dims(x_test, -1)  # 채널 차원 추가\n",
    "# y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "# y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 17472, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 연합학습을 위한 데이터 분할\n",
    "num_clients = 5\n",
    "client_data_size = len(x_train) // num_clients\n",
    "client_data = [(x_train[i * client_data_size: (i + 1) * client_data_size],\n",
    "                y_train[i * client_data_size: (i + 1) * client_data_size])\n",
    "               for i in range(num_clients)]\n",
    "# len(client_data)\n",
    "client_data[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        LSTM(256, activation='relu', input_shape=(x_train.shape[1], x_train.shape[2]), return_sequences=True),\n",
    "        LSTM(16),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jwheo/Projects/etc_project/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17472</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">312,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">17,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17472\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │       \u001b[38;5;34m312,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │        \u001b[38;5;34m17,472\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">329,809</span> (1.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m329,809\u001b[0m (1.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">329,809</span> (1.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m329,809\u001b[0m (1.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클라이언트 모델 초기화\n",
    "def initialize_client_models(num_clients, global_weights=None):\n",
    "    client_models = []\n",
    "    for _ in range(num_clients):\n",
    "        model = create_model()\n",
    "        if global_weights is not None:\n",
    "            model.set_weights(global_weights)  # 모든 클라이언트 모델에 동일한 글로벌 가중치 설정\n",
    "        client_models.append(model)\n",
    "    return client_models\n",
    "\n",
    "# FedAvg로 글로벌 모델 업데이트 함수\n",
    "def federated_averaging(client_models, client_data):\n",
    "    global_model = create_model()\n",
    "    \n",
    "    # 클라이언트 데이터 샘플 수를 기준으로 가중치 계산\n",
    "    num_samples = [data[0].shape[0] for data in client_data]\n",
    "    total_samples = sum(num_samples)\n",
    "    client_weights = [samples / total_samples for samples in num_samples]\n",
    "    \n",
    "    # 각 클라이언트의 가중치를 평균화\n",
    "    model_weights = [model.get_weights() for model in client_models]\n",
    "    average_weights = []\n",
    "    for weights_list in zip(*model_weights):\n",
    "        average_weights.append(np.average(weights_list, axis=0, weights=client_weights))\n",
    "    \n",
    "    global_model.set_weights(average_weights)\n",
    "    return global_model\n",
    "\n",
    "# 각 클라이언트 모델 학습 함수\n",
    "def train_client_model(client_data, model, epochs=1, batch_size=16):\n",
    "    history = model.fit(client_data[0], client_data[1], epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "    return history\n",
    "\n",
    "def evaluate_global(model, x_test, y_test):\n",
    "    total_test_loss = 0.0\n",
    "    total_test_acc = 0.0\n",
    "    for (x_ev, y_ev) in zip(x_test, y_test):\n",
    "        test_loss, test_acc = model.evaluate(x_ev, y_ev, verbose=0)\n",
    "        total_test_loss += test_loss\n",
    "        total_test_acc += test_acc\n",
    "\n",
    "    return total_test_loss/(len(x_test)), total_test_acc/(len(y_test))\n",
    "        \n",
    "# 연합 학습 반복 함수\n",
    "def federated_learning(num_rounds, num_clients, client_data):\n",
    "    # 초기 글로벌 모델 설정\n",
    "    global_model = create_model()\n",
    "    global_model_accuracies = []\n",
    "    \n",
    "    for round in range(num_rounds):\n",
    "        print(f\"Round {round + 1}/{num_rounds}\")\n",
    "        \n",
    "        # 클라이언트 모델 초기화\n",
    "        client_models = initialize_client_models(num_clients, global_weights=global_model.get_weights())\n",
    "        \n",
    "        # 클라이언트 모델 학습\n",
    "        for i in range(num_clients):\n",
    "            print(f\"Training client model {i + 1}...\")\n",
    "            train_client_model(client_data[i], client_models[i])\n",
    "        '''\n",
    "        # FedAvg로 글로벌 모델 생성\n",
    "        global_model = federated_averaging(client_models, client_data)\n",
    "        \n",
    "        # 글로벌 모델 평가\n",
    "        # test_loss, test_acc = global_model.evaluate(x_test[0], y_test[0], verbose=0)\n",
    "        test_loss, test_acc = evaluate_global(global_model, x_test, y_test)\n",
    "        global_model_accuracies.append(test_acc * 100)\n",
    "        print(f'Global model test accuracy: {test_acc * 100:.2f}%')\n",
    "        \n",
    "        # 학습 상황 및 최종 결과 그래프\n",
    "        # client_accuracies = [model.evaluate(x_test, y_test, verbose=0)[1] for model in client_models]\n",
    "        client_accuracies = [evaluate_global(model, x_test, y_test)[1] for model in client_models]\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(range(num_clients), client_accuracies, 'bo-', label='Client Models')\n",
    "        plt.axhline(y=test_acc, color='r', linestyle='-', label='Global Model')\n",
    "        plt.xlabel('Client')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title(f'Client Models vs Global Model Accuracy (Round {round + 1})')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        # 특정 테스트 인덱스를 선택하여 예측 결과 시각화\n",
    "        num_samples = x_test.shape[0]\n",
    "        test_index = np.random.randint(num_samples)\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        for i in range(num_clients):\n",
    "            plt.subplot(2, num_clients, i + 1)\n",
    "            plt.imshow(x_test[test_index].squeeze(), cmap='gray')\n",
    "            client_prediction = np.argmax(client_models[i].predict(x_test[test_index:test_index+1]))\n",
    "            true_label = np.argmax(y_test[test_index])\n",
    "            plt.title(f\"Client {i+1}\\nPred: {client_prediction}\\nTrue: {true_label}\")\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.subplot(2, num_clients, num_clients + 1)\n",
    "        plt.imshow(x_test[test_index].squeeze(), cmap='gray')\n",
    "        global_prediction = np.argmax(global_model.predict(x_test[test_index:test_index+1]))\n",
    "        true_label = np.argmax(y_test[test_index])\n",
    "        plt.title(f\"Global Model\\nPred: {global_prediction}\\nTrue: {true_label}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "        '''\n",
    "\n",
    "    return global_model, global_model_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 17472, 48, 1) (99, 17472, 1)\n",
      "Round 1/1\n",
      "Training client model 1...\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 94s/step - loss: 0.0034\n",
      "Training client model 2...\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 60s/step - loss: 0.0059\n",
      "Training client model 3...\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 70s/step - loss: 0.0045\n",
      "Training client model 4...\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 68s/step - loss: 0.0048\n",
      "Training client model 5...\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x1345671c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 83s/step - loss: 0.0032\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "# 연합 학습 수행\n",
    "num_rounds = 1\n",
    "global_model, global_model_accuracies = federated_learning(num_rounds, num_clients, client_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 17472)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling LSTMCell.call().\n\n\u001b[1mDimensions must be equal, but are 1 and 48 for '{{node sequential_2_1/lstm_4_1/lstm_cell_1/MatMul}} = MatMul[T=DT_FLOAT, grad_a=false, grad_b=false, transpose_a=false, transpose_b=false](sequential_2_1/lstm_4_1/strided_slice_1, sequential_2_1/lstm_4_1/lstm_cell_1/Cast/ReadVariableOp)' with input shapes: [32,1], [48,1024].\u001b[0m\n\nArguments received by LSTMCell.call():\n  • inputs=tf.Tensor(shape=(32, 1), dtype=float32)\n  • states=('tf.Tensor(shape=(32, 256), dtype=float32)', 'tf.Tensor(shape=(32, 256), dtype=float32)')\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_test\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 최종 글로벌 모델 평가\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# test_loss, test_acc = global_model.evaluate(x_test, y_test, verbose=0)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_global\u001b[49m\u001b[43m(\u001b[49m\u001b[43mglobal_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinal global model test accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# 라운드에 따른 글로벌 모델 정확도 변화 그래프\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[25], line 38\u001b[0m, in \u001b[0;36mevaluate_global\u001b[0;34m(model, x_test, y_test)\u001b[0m\n\u001b[1;32m     36\u001b[0m total_test_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (x_ev, y_ev) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(x_test, y_test):\n\u001b[0;32m---> 38\u001b[0m     test_loss, test_acc \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_ev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_ev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     total_test_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m test_loss\n\u001b[1;32m     40\u001b[0m     total_test_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m test_acc\n",
      "File \u001b[0;32m~/Projects/etc_project/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Projects/etc_project/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling LSTMCell.call().\n\n\u001b[1mDimensions must be equal, but are 1 and 48 for '{{node sequential_2_1/lstm_4_1/lstm_cell_1/MatMul}} = MatMul[T=DT_FLOAT, grad_a=false, grad_b=false, transpose_a=false, transpose_b=false](sequential_2_1/lstm_4_1/strided_slice_1, sequential_2_1/lstm_4_1/lstm_cell_1/Cast/ReadVariableOp)' with input shapes: [32,1], [48,1024].\u001b[0m\n\nArguments received by LSTMCell.call():\n  • inputs=tf.Tensor(shape=(32, 1), dtype=float32)\n  • states=('tf.Tensor(shape=(32, 256), dtype=float32)', 'tf.Tensor(shape=(32, 256), dtype=float32)')\n  • training=False"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)\n",
    "# 최종 글로벌 모델 평가\n",
    "# test_loss, test_acc = global_model.evaluate(x_test, y_test, verbose=0)\n",
    "test_loss, test_acc = evaluate_global(global_model, x_test, y_test)\n",
    "print(f'Final global model test accuracy: {test_acc * 100:.2f}%')\n",
    "\n",
    "# 라운드에 따른 글로벌 모델 정확도 변화 그래프\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, num_rounds + 1), global_model_accuracies, 'r-o', label='Global Model Accuracy')\n",
    "plt.xlabel('Round')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Global Model Accuracy Over Rounds')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
